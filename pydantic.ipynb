{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Evaluation, CriteraFeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduction': FieldInfo(annotation=CriteraFeedback, required=True, description='Analysis of the introduction of the essay with these criteria: 1. Clarity of thesis statement, 2. Engagement and relevance of opening statements'),\n",
       " 'structure': FieldInfo(annotation=CriteraFeedback, required=True, description=\"Analasis of the structure of the essay's body with these criteria: 1. Organization and clarity of paragraphs, 2. Logical flow of ideas\"),\n",
       " 'argumentation': FieldInfo(annotation=CriteraFeedback, required=True, description='Analysis of the argumentation of the essay with these criteria: 1. Strength and clarity of arguments, 2. Use of critical reasoning'),\n",
       " 'evidence': FieldInfo(annotation=CriteraFeedback, required=True, description='Analysis of the evidence used in the essay with these criteria: 1. Relevance and quality of evidence, 2. Use of citations and references'),\n",
       " 'conclusion': FieldInfo(annotation=CriteraFeedback, required=True, description='Analysis of the conclusion of the essay with these criteria: 1. Restatement of thesis, 2. Summary of main points, 3. Closing statements')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strengths': FieldInfo(annotation=List[str], required=True, description='Concise list of strengths for this criteria'),\n",
       " 'weaknesses': FieldInfo(annotation=List[str], required=True, description='Concise list of weaknesses for this criteria'),\n",
       " 'suggestions': FieldInfo(annotation=List[str], required=True, description='Concise list of suggestions provided that are not weaknesses')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation.model_fields['introduction'].annotation.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type, Dict, Any, get_origin, get_args\n",
    "from pydantic import BaseModel\n",
    "from collections import defaultdict\n",
    "\n",
    "def remove_duplicates(items):\n",
    "    seen = set()\n",
    "    unique_items = []\n",
    "    for item in items:\n",
    "        # Make sure only hashable items (like strings or numbers) are considered for deduplication.\n",
    "        if isinstance(item, (str, int, float, tuple)):\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "                unique_items.append(item)\n",
    "        else:\n",
    "            # Non-hashable items (like dicts) are added directly without deduplication\n",
    "            unique_items.append(item)\n",
    "    return unique_items\n",
    "\n",
    "def aggregate_dict(aggregated: Dict[str, Any], data: Dict[str, Any]):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            if key not in aggregated:\n",
    "                aggregated[key] = []\n",
    "            aggregated[key].extend(value)\n",
    "        elif isinstance(value, dict):\n",
    "            if key not in aggregated:\n",
    "                aggregated[key] = defaultdict(list)\n",
    "            aggregate_dict(aggregated[key], value)\n",
    "\n",
    "def deduplicate_dict(data: Dict[str, Any]):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            data[key] = remove_duplicates(value)\n",
    "        elif isinstance(value, dict):\n",
    "            deduplicate_dict(value)\n",
    "\n",
    "def aggregate_feedback(feedbacks: List[BaseModel], feedback_class: Type[BaseModel]):\n",
    "    def to_dict(obj: Any) -> Any:\n",
    "        if isinstance(obj, BaseModel):\n",
    "            return {k: to_dict(v) for k, v in obj.model_dump().items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [to_dict(v) for v in obj]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def from_dict(cls: Type[BaseModel], data: Dict[str, Any]) -> BaseModel:\n",
    "        field_values = {}\n",
    "        for name, field in cls.model_fields.items():\n",
    "            if name in data:\n",
    "                value = data[name]\n",
    "                origin = get_origin(field.annotation)\n",
    "                if origin is not None and issubclass(origin, list):\n",
    "                    field_type = get_args(field.annotation)[0]\n",
    "                    if issubclass(field_type, BaseModel):\n",
    "                        field_values[name] = [from_dict(field_type, v) for v in value]\n",
    "                    else:\n",
    "                        field_values[name] = value\n",
    "                elif isinstance(field.annotation, type) and issubclass(field.annotation, BaseModel):\n",
    "                    field_values[name] = from_dict(field.annotation, value)\n",
    "                else:\n",
    "                    field_values[name] = value\n",
    "        return cls(**field_values)\n",
    "\n",
    "    # Initialize the aggregated structure dynamically\n",
    "    aggregated = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Aggregate all feedbacks\n",
    "    for feedback in feedbacks:\n",
    "        feedback_dict = to_dict(feedback)\n",
    "        aggregate_dict(aggregated, feedback_dict)\n",
    "\n",
    "    # Deduplicate lists\n",
    "    deduplicate_dict(aggregated)\n",
    "\n",
    "    # Construct a new feedback object dynamically\n",
    "    return from_dict(feedback_class, aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(introduction=CriteraFeedback(strengths=['s1', 's2', 's11', 's22'], weaknesses=['w1', 'w2', 'w11', 'w22'], suggestions=['ss1, ss2', 'ss11, ss2']), structure=CriteraFeedback(strengths=['s1', 's2'], weaknesses=['w1', 'w2'], suggestions=['ss1, ss2']), argumentation=CriteraFeedback(strengths=['s1', 's2'], weaknesses=['w1', 'w2'], suggestions=['ss1, ss2']), evidence=CriteraFeedback(strengths=['s1', 's2'], weaknesses=['w1', 'w2'], suggestions=['ss1, ss2']), conclusion=CriteraFeedback(strengths=['s1', 's2'], weaknesses=['w1', 'w2'], suggestions=['ss1, ss2']))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "aggregate_feedback(\n",
    "    feedback_class=Evaluation,\n",
    "    feedbacks=[\n",
    "        Evaluation(\n",
    "            introduction=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            structure=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            argumentation=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            evidence=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            conclusion=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "        ),\n",
    "        Evaluation(\n",
    "            introduction=CriteraFeedback(\n",
    "                strengths=[\"s11\", \"s22\"],\n",
    "                weaknesses=[\"w11\", \"w22\"],\n",
    "                suggestions=[\"ss11, ss2\"],\n",
    "            ),\n",
    "            structure=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            argumentation=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            evidence=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "            conclusion=CriteraFeedback(\n",
    "                strengths=[\"s1\", \"s2\"],\n",
    "                weaknesses=[\"w1\", \"w2\"],\n",
    "                suggestions=[\"ss1, ss2\"],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classroom-lm-poc-GKspPBel-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
